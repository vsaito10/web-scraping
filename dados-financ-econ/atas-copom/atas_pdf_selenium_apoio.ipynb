{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informações das atas do COPOM**\n",
    "\n",
    "* Atas: https://www.bcb.gov.br/publicacoes/atascopom/cronologicos\n",
    "\n",
    "    * De janeiro/1998 até junho/2016, as atas não possuem o arquivo PDF formatado na mesma estrutura que existe atualmente;\n",
    "    * A partir de julho/2016 até os dias de hoje, as atas são divulgadas em um arquivo PDF.\n",
    "\n",
    "---\n",
    "\n",
    "* Minutes: https://www.bcb.gov.br/en/publications/copomminutes/cronologicos\n",
    "\n",
    "    * O número de atas publicadas em inglês é diferente das atas publicadas em português. A primeira ata (nº 42) publicada em inglês é de 01/2000;\n",
    "    * Desde o começo das suas publicações em inglês, os arquivos já possuiam um arquivo PDF.\n",
    "\n",
    "---\n",
    "\n",
    "**Estrutura do texto em português - atual**\n",
    "\n",
    "* A) Atualização da conjuntura econômica e do cenário básico do Copom1\n",
    "* B) Riscos em torno do cenário básico para a inflação\n",
    "* C) Discussão sobre a condução da política monetária\n",
    "* D) Decisão de política monetária\n",
    "\n",
    "---\n",
    "\n",
    "**Estrutura do texto em inglês - atual**\n",
    "   \n",
    "* A) Update of economic outlook and Copom’s baseline scenario1\n",
    "* B) Scenarios and risk analysis\n",
    "* C) Discussion about the conduct of monetary policy\n",
    "* D) Monetary policy decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações auxiliares para rodar o script 'atas_pdf_selenium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para rodar o script que faz o download dos arquivos pdfs das atas, eu preciso adicionar a data de publicação da ata na URL -> https://www.bcb.gov.br/en/publications/copomminutes/{date_minute};\n",
    "* Essas datas são os valores do dicionário ('dict_ata').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'257': '20092023',\n",
       " '256': '02082023',\n",
       " '255': '21062023',\n",
       " '254': '03052023',\n",
       " '253': '22032023',\n",
       " '252': '01022023',\n",
       " '251': '07122022',\n",
       " '250': '26102022',\n",
       " '249': '21092022',\n",
       " '248': '03082022',\n",
       " '247': '15062022',\n",
       " '246': '04052022',\n",
       " '245': '16032022',\n",
       " '244': '02022022',\n",
       " '243': '08122021',\n",
       " '242': '27102021',\n",
       " '241': '22092021',\n",
       " '240': '04082021',\n",
       " '239': '16062021',\n",
       " '238': '05052021',\n",
       " '237': '17032021',\n",
       " '236': '20012021',\n",
       " '235': '09122020',\n",
       " '234': '28102020',\n",
       " '233': '16092020',\n",
       " '232': '05082020',\n",
       " '231': '17062020',\n",
       " '230': '06052020',\n",
       " '229': '18032020',\n",
       " '228': '05022020',\n",
       " '227': '11122019',\n",
       " '226': '30102019',\n",
       " '225': '18092019',\n",
       " '224': '31072019',\n",
       " '223': '19062019',\n",
       " '222': '08052019',\n",
       " '221': '21032019',\n",
       " '220': '06022019',\n",
       " '219': '12122018',\n",
       " '218': '31102018',\n",
       " '217': '19092018',\n",
       " '216': '01082018',\n",
       " '215': '20062018',\n",
       " '214': '16052018',\n",
       " '213': '27032018',\n",
       " '212': '15022018',\n",
       " '211': '12122017',\n",
       " '210': '31102017',\n",
       " '209': '13092017',\n",
       " '208': '01072017',\n",
       " '207': '06052017',\n",
       " '206': '18042017',\n",
       " '205': '02022017',\n",
       " '204': '17012017',\n",
       " '203': '06112016',\n",
       " '202': '25102016',\n",
       " '201': '31082016',\n",
       " '200': '01072016',\n",
       " '199': '21062016',\n",
       " '198': '11052016',\n",
       " '197': '18032016',\n",
       " '196': '03012016',\n",
       " '195': '25112015',\n",
       " '194': '05102015',\n",
       " '193': '16092015',\n",
       " '192': '13082015',\n",
       " '191': '17062015',\n",
       " '190': '14042015',\n",
       " '189': '19032015',\n",
       " '188': '04012015',\n",
       " '187': '17122014',\n",
       " '186': '12102014',\n",
       " '185': '16092014',\n",
       " '184': '30072014',\n",
       " '183': '13052014',\n",
       " '182': '15042014',\n",
       " '181': '13022014',\n",
       " '180': '31012014',\n",
       " '179': '13112013',\n",
       " '178': '24102013',\n",
       " '177': '13082013',\n",
       " '176': '25072013',\n",
       " '175': '29052013',\n",
       " '174': '06042013',\n",
       " '173': '22032013',\n",
       " '172': '16012013',\n",
       " '171': '12122012',\n",
       " '170': '25102012',\n",
       " '169': '14082012',\n",
       " '168': '26072012',\n",
       " '167': '18052012',\n",
       " '166': '07042012',\n",
       " '165': '23032012',\n",
       " '164': '07012012',\n",
       " '163': '16112011',\n",
       " '162': '08102011',\n",
       " '161': '14082011',\n",
       " '160': '05072011',\n",
       " '159': '21062011',\n",
       " '158': '05042011',\n",
       " '157': '22032011',\n",
       " '156': '08012011',\n",
       " '155': '27122010',\n",
       " '154': '11102010',\n",
       " '153': '24092010',\n",
       " '152': '05072010',\n",
       " '151': '22062010',\n",
       " '150': '12042010',\n",
       " '149': '19032010',\n",
       " '148': '09012010',\n",
       " '147': '06122009',\n",
       " '146': '20102009',\n",
       " '145': '01092009',\n",
       " '144': '01072009',\n",
       " '143': '01062009',\n",
       " '142': '29042009',\n",
       " '141': '01032009',\n",
       " '140': '01012009',\n",
       " '139': '01122008',\n",
       " '138': '29102008',\n",
       " '137': '10092008',\n",
       " '136': '23072008',\n",
       " '135': '01062008',\n",
       " '134': '16042008',\n",
       " '133': '01032008',\n",
       " '132': '01012008',\n",
       " '131': '01122007',\n",
       " '130': '01102007',\n",
       " '129': '01092007',\n",
       " '128': '01072007',\n",
       " '127': '01062007',\n",
       " '126': '01042007',\n",
       " '125': '01032007',\n",
       " '124': '01012007',\n",
       " '123': '01112006',\n",
       " '122': '01102006',\n",
       " '121': '01082006',\n",
       " '120': '01072006',\n",
       " '119': '31052006',\n",
       " '118': '01042006',\n",
       " '117': '01032006',\n",
       " '116': '01012006',\n",
       " '115': '01122005',\n",
       " '114': '01112005',\n",
       " '113': '01102005',\n",
       " '112': '01092005',\n",
       " '111': '01082005',\n",
       " '110': '01072005',\n",
       " '109': '01062005',\n",
       " '108': '01052005',\n",
       " '107': '29042005',\n",
       " '106': '01032005',\n",
       " '105': '01022005',\n",
       " '104': '01012005',\n",
       " '103': '01122004',\n",
       " '102': '01112004',\n",
       " '101': '28102004',\n",
       " '100': '30092004',\n",
       " '99': '18082004',\n",
       " '98': '29072004',\n",
       " '97': '25062004',\n",
       " '96': '28052004',\n",
       " '95': '26042004',\n",
       " '94': '30032004',\n",
       " '93': '27022004',\n",
       " '92': '30012004',\n",
       " '91': '24122003',\n",
       " '90': '28112003',\n",
       " '89': '31102003',\n",
       " '88': '25092003',\n",
       " '87': '29082003',\n",
       " '86': '31072003',\n",
       " '85': '27062003',\n",
       " '84': '30052003',\n",
       " '83': '30042003',\n",
       " '82': '27032003',\n",
       " '81': '26022003',\n",
       " '80': '30012003',\n",
       " '79': '27122002',\n",
       " '78': '29112002',\n",
       " '77': '01112002',\n",
       " '76': '18102002',\n",
       " '75': '27092002',\n",
       " '74': '30082002',\n",
       " '73': '26072002',\n",
       " '72': '28062002',\n",
       " '71': '03062002',\n",
       " '70': '29042002',\n",
       " '69': '01042002',\n",
       " '68': '04032002',\n",
       " '67': '04022002',\n",
       " '66': '03012002',\n",
       " '65': '03122001',\n",
       " '64': '30102001',\n",
       " '63': '28092001',\n",
       " '62': '03092001',\n",
       " '61': '30072001',\n",
       " '60': '03072001',\n",
       " '59': '01062001',\n",
       " '58': '27042001',\n",
       " '57': '29032001',\n",
       " '56': '28032001',\n",
       " '55': '21022001',\n",
       " '54': '10012001',\n",
       " '53': '07122000',\n",
       " '52': '01112000',\n",
       " '51': '04102000',\n",
       " '50': '12092000',\n",
       " '49': '01082000',\n",
       " '48': '06072000',\n",
       " '47': '09062000',\n",
       " '46': '04052000',\n",
       " '45': '30032000',\n",
       " '44': '15022000',\n",
       " '43': '04022000',\n",
       " '42': '10012000'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dados do request da página do BC -> 'Inspecionar' -> 'Network' -> 'Fetch/XHR' -> 'Atualiza a página' -> endpoint 'ultimas?quantidade=1000&filtro' \n",
    "url = \"https://www.bcb.gov.br/api/servico/sitebcb/copomminutes/ultimas\"\n",
    "\n",
    "querystring = {\"quantidade\":\"1000\",\"filtro\":\"\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\"sec-ch-ua\": \"^\\^Chromium^^;v=^\\^116^^, ^\\^Not\"}\n",
    "\n",
    "r = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "data = r.json()\n",
    "\n",
    "# Lista com os títulos das atas\n",
    "lst_titulo = [item['Titulo'] for item in data['conteudo']]\n",
    "\n",
    "# Removendo da lista o título do pdf 'Changes in Copom meetings'\n",
    "string_a_remover = 'Changes in Copom meetings'\n",
    "\n",
    "if string_a_remover in lst_titulo:\n",
    "    lst_titulo.remove(string_a_remover)\n",
    "else:\n",
    "    print(f'A string {string_a_remover} não está na lista.')\n",
    "\n",
    "# Selecionando apenas o número da ata do título\n",
    "# Observação: o título da ata 210 ('210 Copom Minutes') é o único que não tem o 'th' após o número da ata -> '210 th'\n",
    "# Esse diferença estava zoando o código, porque eu estava fazendo o regex para selecionar o número antes de 'st', 'nd', 'rd' e 'th'\n",
    "# Quando eu percebi essa discrepância no título da ata 210, eu consegui arrumar o regex para selecionar os números inicias de cada string\n",
    "lst_titulo = [re.findall(r'^\\d+', item)[0] if re.findall(r'^\\d+', item) else None for item in lst_titulo]\n",
    "\n",
    "\n",
    "# Lista com as datas das publicações das atas\n",
    "lst_data_pub = [item['DataReferencia'] for item in data['conteudo']]\n",
    "\n",
    "# Removendo da lista a data que corresponde ao pdf 'Changes in Copom meetings'\n",
    "data_a_remover = '2000-01-19T02:00:00Z'\n",
    "\n",
    "if data_a_remover in lst_data_pub:\n",
    "    lst_data_pub.remove(data_a_remover)\n",
    "else:\n",
    "    print(f'A string {data_a_remover} não está na lista.')\n",
    "\n",
    "# Usando regex para encontrar todas as datas no formato 'yyyy-mm-dd' na lista\n",
    "padrao_data = r'\\d{4}-\\d{2}-\\d{2}'\n",
    "lst_data_pub = re.findall(padrao_data, ' '.join(lst_data_pub))\n",
    "\n",
    "# Removendo os traços '-' de cada data\n",
    "lst_data_pub = [data.replace('-', '') for data in lst_data_pub]\n",
    "\n",
    "# Revertendo a ordem das datas para 'ddmmyyyy'\n",
    "lst_data_pub = [data[6:] + data[4:6] + data[:4] for data in lst_data_pub]\n",
    "\n",
    "\n",
    "# Criando um dicionário que contém todas as atas disponíveis\n",
    "dict_ata = dict(zip(lst_titulo, lst_data_pub))\n",
    "dict_ata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eu não quero fazer o download de todos os arquivos PDF ao mesmo tempo. Para fazer os download das atas em partes, eu tenho que descobrir a posição da ata na lista 'lst_data_pub';\n",
    "* Eu criei o 'dict_ata' para ajudar na visualização para saber qual é a data de publicação correspondente com o nº da ata;\n",
    "* A 'lst_data_pub' contém apenas as datas de publicações;\n",
    "* Na 'lst_data_pub', o primeiro valor 'lst_data_pub[0]' sempre é a ata mais atual.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17062020']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_data_pub[26:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O número máximo que eu consigo iterar é o 'len(lst_data_pub)' que é igual ao 'len(dict_ata)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número total é de 216 atas.\n",
      "O número total é de 216 atas.\n"
     ]
    }
   ],
   "source": [
    "# Número total de atas disponíveis\n",
    "print(f'O número total é de {len(dict_ata)} atas.')\n",
    "print(f'O número total é de {len(lst_data_pub)} atas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Descobrindo qual é a posição na lista de uma ata específica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ata nº 200 está na posição 57 do dicionário.\n"
     ]
    }
   ],
   "source": [
    "# Número da ata que você deseja encontrar\n",
    "numero_da_ata = '200'\n",
    "\n",
    "# Verificar a posição da ata no dicionário\n",
    "posicao = None\n",
    "for i, chave in enumerate(dict_ata.keys(), start=1):\n",
    "    if chave == numero_da_ata:\n",
    "        posicao = i\n",
    "        break\n",
    "\n",
    "if posicao is not None:\n",
    "    print(f\"A ata nº {numero_da_ata} está na posição {posicao - 1} do dicionário.\")\n",
    "else:\n",
    "    print(f\"A ata nº {numero_da_ata} não foi encontrada no dicionário.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agora que sabemos qual é a posição de uma ata específica eu posso criar um slice na lista;\n",
    "* Exemplo: ata nº 42 (primeira ata publicada pelo BC, ela está na última posição da lista) até a ata nº 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12122017',\n",
       " '31102017',\n",
       " '13092017',\n",
       " '01072017',\n",
       " '06052017',\n",
       " '18042017',\n",
       " '02022017',\n",
       " '17012017',\n",
       " '06112016',\n",
       " '25102016',\n",
       " '31082016']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista com as datas de publicações de todas as atas\n",
    "lst_data_pub[46:57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se as datas do slicing estiverem corretas. Agora, basta ir para o script 'atas_pdf_selenium' e colocar esses números nos parâmetros 'pos_ata_inicial' e 'pos_ata_final' da função 'download_arquivo'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renomeando os nomes dos arquivos das atas do COPOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_download = r\"C:\\Users\\vitor\\projetos_python\\python_b3\\historico-arquivos\\minutes-pdf\"\n",
    "\n",
    "arquivos = glob.glob(os.path.join(path_download, '*.pdf'))\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    # Selecionando apenas os nomes do arquivo\n",
    "    nome_do_arquivo = os.path.basename(arquivo)\n",
    "\n",
    "    # Padrão do nome: 'min200042-copom20000110-42nd_copom_minutes.pdf'\n",
    "    if nome_do_arquivo.startswith('min2000'):\n",
    "        # Selecionando apenas o nº da ata que vem antes de rt|nd|rd|th\n",
    "        padrao = r'(\\d+)(?:rt|nd|rd|th)'\n",
    "        correspondencias = re.findall(padrao, nome_do_arquivo)\n",
    "        num_ata = correspondencias[0]\n",
    "        novo_nome = f\"minutes_{num_ata}.pdf\"\n",
    "        \n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "\n",
    "    # Padrão do nome: 'min20190731224.pdf'\n",
    "    if nome_do_arquivo.startswith('min2019'):\n",
    "        # Selecionando apenas o nº da ata (três digitos que vem antes de um ponto final)\n",
    "        padrao = r'\\d{3}(?=\\.)'\n",
    "        correspondencias = re.findall(padrao, nome_do_arquivo)\n",
    "        num_ata = correspondencias[0]\n",
    "        novo_nome = f\"minutes_{num_ata}.pdf\"\n",
    "        \n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "\n",
    "    # Padrão do nome: 'Copom Minutes 230.pdf'\n",
    "    if nome_do_arquivo.startswith('Copom Minutes'):\n",
    "        # Substituindo espaços em branco por underscores, convertendo para letras minúsculas e retirando o 'copom_'\n",
    "        novo_nome = nome_do_arquivo.replace(' ', '_').lower().replace('copom_', '')\n",
    "\n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "    \n",
    "    # Padrão do nome: 'Copom 229 Minutes.pdf'\n",
    "    if nome_do_arquivo.startswith('Copom 229'):\n",
    "        # Substituindo espaços em branco por underscores, convertendo para letras minúsculas e retirando o 'copom_'\n",
    "        novo_nome = nome_do_arquivo.replace(' ', '_').lower().replace('copom_', '')\n",
    "        # Invertendo '229_minutes.pdf' p/ 'minutes_229.pdf'\n",
    "        partes = novo_nome.split(\"_\")\n",
    "        novo_nome = partes[1].replace(\".pdf\", \"\") + \"_\" + partes[0] + \".pdf\"\n",
    "\n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "\n",
    "    # Padrão do nome: 'MINUTES227-min20191211227.pdf'\n",
    "    if nome_do_arquivo.startswith('MINUTES227'):\n",
    "        # Dividindo a string com base no traço (-) p/ pegar a primeira parte 'MINUTES227'\n",
    "        partes = nome_do_arquivo.split('-')\n",
    "        novo_nome = partes[0] + '.pdf'\n",
    "        # Convertendo para letras minúsculas\n",
    "        novo_nome = novo_nome.lower()\n",
    "        # Adionando o score no meio da string -> 'minutes_227'\n",
    "        novo_nome = re.sub(r'(\\d+)', r'_\\1', novo_nome)\n",
    "\n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "    \n",
    "    # Padrão do nome: 'MINUTES 226.pdf'\n",
    "    if nome_do_arquivo.startswith('MINUTES'):\n",
    "        # Substituindo espaços em branco por underscores e convertendo para letras minúsculas\n",
    "        novo_nome = nome_do_arquivo.replace(' ', '_').lower()\n",
    "\n",
    "        # Renomeando o nome dos arquivos\n",
    "        caminho_atual = os.path.join(path_download, nome_do_arquivo)\n",
    "        novo_caminho = os.path.join(path_download, novo_nome)\n",
    "        os.rename(caminho_atual, novo_caminho)\n",
    "        \n",
    "        print(novo_nome)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padrão do nome: 'MINUTES227-min20191211227.pdf'\n",
    "padrao = r'MINUTES\\d+-min\\d+\\.pdf'\n",
    "# Padrão do nome: 'MINUTES218-min20181031218'\n",
    "padrao_2 = r'MIN2018\\d+'\n",
    "# Padrão do nome: 'MIN2017211th-COPOM20171205-211th_Copom_Minutes'\n",
    "padrao_3 = r'MIN2017\\d+'\n",
    "# Padrão do nome: 'MIN2016203rd-COPOM20161206-203rd_Copom_Minutes'\n",
    "padrao_4 = r'MIN2016\\d+'\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    nome_arquivo = os.path.basename(arquivo).lower()\n",
    "\n",
    "    # Strings correpondentes com o padrão regex\n",
    "    correspondencias = re.findall(padrao, nome_arquivo, re.IGNORECASE)\n",
    "    correspondencias_2 = re.findall(padrao_2, nome_arquivo, re.IGNORECASE)\n",
    "    correspondencias_3 = re.findall(padrao_3, nome_arquivo, re.IGNORECASE)\n",
    "    correspondencias_4 = re.findall(padrao_4, nome_arquivo, re.IGNORECASE)\n",
    "\n",
    "    if correspondencias:\n",
    "        for correspondencia in correspondencias:\n",
    "            # Separando a string no '-'\n",
    "            partes = correspondencia.split('-')\n",
    "            # Adicionando '.pdf' na string\n",
    "            novo_nome = partes[0] + '.pdf'\n",
    "            # Adicionando o underscore entre a palavra 'minutes' e o número da ata\n",
    "            novo_nome = novo_nome.replace('minutes', 'minutes_')\n",
    "            # Construindo o novo caminho\n",
    "            novo_caminho = os.path.join(path_download, novo_nome)\n",
    "            # Renomeando o arquivo\n",
    "            os.rename(arquivo, novo_caminho)\n",
    "    \n",
    "    if correspondencias_2:\n",
    "        for correspondencia in correspondencias_2:\n",
    "            # Adicionando '.pdf' na string\n",
    "            novo_nome = correspondencia + '.pdf'\n",
    "            # Substituindo a palavra 'min2018' por 'minutes_'\n",
    "            novo_nome = novo_nome.replace('min2018', 'minutes_')\n",
    "            # Construindo o novo caminho\n",
    "            novo_caminho = os.path.join(path_download, novo_nome)\n",
    "            # Renomeando o arquivo\n",
    "            os.rename(arquivo, novo_caminho)\n",
    "\n",
    "    if correspondencias_3:\n",
    "        for correspondencia in correspondencias_3:\n",
    "            # Adicionando '.pdf' na string\n",
    "            novo_nome = correspondencia + '.pdf'\n",
    "            # Substituindo a palavra 'min2018' por 'minutes_'\n",
    "            novo_nome = novo_nome.replace('min2017', 'minutes_')\n",
    "            # Construindo o novo caminho\n",
    "            novo_caminho = os.path.join(path_download, novo_nome)\n",
    "            # Renomeando o arquivo\n",
    "            os.rename(arquivo, novo_caminho)\n",
    "\n",
    "    if correspondencias_4:\n",
    "        for correspondencia in correspondencias_4:\n",
    "            # Adicionando '.pdf' na string\n",
    "            novo_nome = correspondencia + '.pdf'\n",
    "            # Substituindo a palavra 'min2018' por 'minutes_'\n",
    "            novo_nome = novo_nome.replace('min2016', 'minutes_')\n",
    "            # Construindo o novo caminho\n",
    "            novo_caminho = os.path.join(path_download, novo_nome)\n",
    "            # Renomeando o arquivo\n",
    "            os.rename(arquivo, novo_caminho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minutes_200.pdf\n",
      "minutes_201.pdf\n",
      "minutes_202.pdf\n",
      "minutes_203.pdf\n",
      "minutes_204.pdf\n",
      "minutes_205.pdf\n",
      "minutes_206.pdf\n",
      "minutes_207.pdf\n",
      "minutes_208.pdf\n",
      "minutes_209.pdf\n",
      "minutes_210.pdf\n",
      "minutes_211.pdf\n",
      "minutes_212.pdf\n",
      "minutes_213.pdf\n",
      "minutes_214.pdf\n",
      "minutes_215.pdf\n",
      "minutes_216.pdf\n",
      "minutes_217.pdf\n",
      "minutes_218.pdf\n",
      "minutes_219.pdf\n",
      "minutes_220.pdf\n",
      "minutes_221.pdf\n",
      "minutes_222.pdf\n",
      "minutes_223.pdf\n",
      "minutes_224.pdf\n",
      "minutes_225.pdf\n",
      "minutes_226.pdf\n",
      "minutes_227.pdf\n",
      "minutes_228.pdf\n",
      "minutes_229.pdf\n",
      "minutes_230.pdf\n",
      "minutes_231.pdf\n",
      "minutes_232.pdf\n",
      "minutes_233.pdf\n",
      "minutes_234.pdf\n",
      "minutes_235.pdf\n",
      "minutes_236.pdf\n",
      "minutes_237.pdf\n",
      "minutes_238.pdf\n",
      "minutes_239.pdf\n",
      "minutes_240.pdf\n",
      "minutes_241.pdf\n",
      "minutes_242.pdf\n",
      "minutes_243.pdf\n",
      "minutes_244.pdf\n",
      "minutes_245.pdf\n",
      "minutes_246.pdf\n",
      "minutes_247.pdf\n",
      "minutes_248.pdf\n",
      "minutes_249.pdf\n",
      "minutes_250.pdf\n",
      "minutes_251.pdf\n",
      "minutes_252.pdf\n",
      "minutes_253.pdf\n",
      "minutes_254.pdf\n",
      "minutes_255.pdf\n",
      "minutes_256.pdf\n",
      "minutes_257.pdf\n",
      "minutes_42.pdf\n",
      "minutes_43.pdf\n",
      "minutes_44.pdf\n",
      "minutes_45.pdf\n",
      "minutes_46.pdf\n",
      "minutes_47.pdf\n",
      "minutes_48.pdf\n",
      "minutes_49.pdf\n"
     ]
    }
   ],
   "source": [
    "path_download = r\"C:\\Users\\vitor\\projetos_python\\python_b3\\historico-arquivos\\minutes-pdf\"\n",
    "\n",
    "arquivos = glob.glob(os.path.join(path_download, '*.pdf'))\n",
    "\n",
    "for arquivo in arquivos:\n",
    "    # Selecionando apenas os nomes do arquivo\n",
    "    nome_do_arquivo = os.path.basename(arquivo)\n",
    "\n",
    "    print(nome_do_arquivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
